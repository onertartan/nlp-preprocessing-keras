{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MrawafSittz"
   },
   "source": [
    "# Content\n",
    "This notebook is the second part of  Data Preparation in NLP using Keras.   \n",
    "  \n",
    " In this notebook firstly we will repeat the steps in the previous notebook<br>\n",
    " Then we will <br>\n",
    " 1\\. Create test texts (test corpus)<br>\n",
    " 2\\. Use  **`texts_to_sequences`** method on test texts (test corpus)<br>\n",
    " 3\\. Create a tokenizer with oov_token and num_words parameters and repeat.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6777,
     "status": "ok",
     "timestamp": 1677398118662,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "phnV6MCnCI0L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "train_texts = [\"You take the blue-pill!\",  \"The story ends.\"]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA0XPCdsCkSc"
   },
   "source": [
    "We have a tokenizer and its word_index,index_word and word_counts dictionaries are filled based on the training corpus.<br>\n",
    "Now we can convert the texts we want to index sequences using texts_to_sequences method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKcRcHKh5IpS"
   },
   "source": [
    "# **1 . Create test texts (test corpus)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QxXzGqrd9Ej"
   },
   "source": [
    "Let's create a test corpus as we created the training corpus previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1677398118663,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "cJrnvq2p464o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_texts = [\"You take the red pill.\",\n",
    "             \"You stay in wonderland.\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lR0WJ_K5G_Q"
   },
   "source": [
    "# **2 .Use `texts_to_sequences` method on test texts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9RylX3B_bNb"
   },
   "source": [
    "* Note that we use `fit_on_texts` method on training corpus and our training corpus did not contain words like **\"red\"** , **\"stay\"**, **\"in\"** and **\"wonderland\"**.\n",
    "* Therefore **word_index** does not contain those words. As a result unknown words are not indexed.<br>\n",
    "Let's remember our word_index dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1677398118664,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "6byteGX_DdZB",
    "outputId": "5f6a006c-9b0a-4179-afc2-240de97c9b7e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1, 'you': 2, 'take': 3, 'blue': 4, 'pill': 5, 'story': 6, 'ends': 7}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Pge3LJCDLpu"
   },
   "source": [
    "Now let's convert test texts to index sequences using texts_to_sequences method and check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1677398118664,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "neteA-Sa53zX",
    "outputId": "b911febf-ed13-4271-bc56-1f1d435744b5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 1, 5], [2]]\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "print(test_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sI4NsOMZ6NTo"
   },
   "source": [
    "\n",
    "* **As a result** when we apply texts_to_sequences on **test texts** these words cannot be represented as indices, hence they are **missing**. The image below depicts it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/Tokenizer_3.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndPgtHFjDLAa"
   },
   "source": [
    "# **3. Create a tokenizer with  `num_words` and `oov_token`  parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yevw3pK5PX3"
   },
   "source": [
    "## 3.1 Tokenizer with **`oov_token`** parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5cczeNZ5Awh"
   },
   "source": [
    "* Above we have seen that tokenizer's  **word_index** dictionary does not contain the unknown words(the words not met before) in the test corpus, because since we fit the tokenizer on training corpus. <br>\n",
    "* When we apply texts_to_sequences on **test texts**, the unkown words are missing in the resulting index sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hqFmNUX6bTv"
   },
   "source": [
    "What if we want to represent unknown words when converting test texts to sequences.<br>\n",
    "We can do this When creating the tokenizer, if we use **oov_token paremeter** which indicates that word is **out of vocabulary** <br>\n",
    "Using **oov_token**:\n",
    "* we initialize tokenizer's **word_index** dictionary  with a special token for unknown(out of vocabulary) words.\n",
    "* Then, we can represent those unknown words, when converting test texts to integer sequences,. <br>So they won't be missing but they will be represented the same integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCq099C18OtO"
   },
   "source": [
    "Let's repeat the steps we have done earlier. But this time we will use oov_token parameter <br> \n",
    "* create a tokenizer (this time using **oov_token** parameter. Let's use represent those out of vocab words as **\\<OOV\\>**)\n",
    "* fit on train_texts\n",
    "* convert texts to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1677398138244,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "rQsf-5ll7Hve"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np1tisLJ9-ZA"
   },
   "source": [
    "Let's print **word_index**, **test_texts** and **test_sequences**. <br>\n",
    "Note: We can skip converting (applying texts_to_sequences method on) train texts to train_sequences, because as expected there is nothing new for train_texts and train_sequences. It is clear that there cannot be out of vocabulary word in train corpus, since the tokenizer is fit on it.<br>\n",
    "In short, using **oov_token** affects conversions of text sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677398139141,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "wgBOHGg3-ml-",
    "outputId": "f01aeacc-9700-4e47-969f-99d2d3c6efb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'the': 2, 'you': 3, 'take': 4, 'blue': 5, 'pill': 6, 'story': 7, 'ends': 8}\n",
      "['You take the red pill.', 'You stay in wonderland.']\n",
      "[[3, 4, 2, 1, 6], [3, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)\n",
    "print(test_texts)\n",
    "print(test_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZXb6vln-2aH"
   },
   "source": [
    "As a result, we can see that the words **\"red\"**, **\"stay\"**, **\"in\"** and **\"wonderland\"** are not ignored, but represented by 1 now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/Tokenizer_4.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pyCKjE05B1N"
   },
   "source": [
    "## 3.2 Tokenizer with **`num_words`** parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew5j7Ulnwx_H"
   },
   "source": [
    "Now let's create train_texts again adding a third sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1677398143798,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "30QyafX6EWoy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts = [\"You take the blue pill.\",\n",
    "             \"The story ends...\",\n",
    "             \"or you take the red pill.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEJzJ18iwwrg"
   },
   "source": [
    "* When creating Tokenizer, **num_words** parameter is used to take the most common num_words-1 words when applying `texts_to_sequences` method  and to ignore less frequent words. <br> \n",
    "* One thing to note is less frequent words are still given indices, but they don't take place in sequences.<br>\n",
    "Let's repeat the steps we have done earlier. But this time we will use num_words <br> \n",
    "  - create a tokenizer (this time using **num_words** parameter. Let's use top 5 words)\n",
    "  - fit on train_texts\n",
    "  - convert texts to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1677398147170,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "6Hshjc-Zwl4n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "defvU2VjyqwZ"
   },
   "source": [
    "Let's print **word_counts** first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1677398157586,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "-EFnjuvFzM5a",
    "outputId": "5f6f835c-fd1d-4709-c325-73b6e9ee2c29",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('you', 2),\n",
       "             ('take', 2),\n",
       "             ('the', 3),\n",
       "             ('blue', 1),\n",
       "             ('pill', 2),\n",
       "             ('story', 1),\n",
       "             ('ends', 1),\n",
       "             ('or', 1),\n",
       "             ('red', 1)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrO75Hux_lgc"
   },
   "source": [
    "Now let's check **word_index**, **train_texts** and **train_sequences**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1677398166228,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "SUU7C1sux6c2",
    "outputId": "96d10f50-f7a9-4a85-8a34-af8deaaf8e8a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'you': 2, 'take': 3, 'pill': 4, 'blue': 5, 'story': 6, 'ends': 7, 'or': 8, 'red': 9}\n",
      "['You take the blue pill.', 'The story ends...', 'or you take the red pill.']\n",
      "[[2, 3, 1, 4], [1], [2, 3, 1, 4]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)\n",
    "print(train_texts)\n",
    "print(train_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./Images/Tokenizer_5.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kml-UvM20gaG"
   },
   "source": [
    "Above\n",
    "* We can see that the top 4 (num_words-1) words are represented as sequences and other words (although they are encoded in word_index) ignored by text_to_sequences method. \n",
    "* Since their counts are 1, the words **blue** (index 5), **story** (index 6), **ends** (represented as 7), **or** (index 8) and **red** (index 9) are ignored (see the sequence for the second sentence) and they don't appear in the integer sequences. In other words they are not in the top 5 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLrD76mAs1FM"
   },
   "source": [
    "## 3.3 Tokenizer with **`num_words`**  and  **oov_token** parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qG3f3tatG3r"
   },
   "source": [
    "* Previously in part 3.1 when we used oov_token, the resulting sequence of the training corpus did not contain oov_token (as expected), **because we set up vocabulary using ALL of the tokens(we did not use num_words) in training corpus.** (No token was left out of vocabulary.) <br><br>\n",
    "* One important thing to pay attention when **using num_words and oov_token together** is that **we can see oov_tokens in the the resulting sequence of the training corpus.**<br><br>\n",
    "* The reason for this is **considering less frequent words(words other than most common num_words-1) as oov_token even if they are in the training corpus.** <br><br>\n",
    "* As a result all the words less frequent than most common (num_words-1) words will take place in the resulting sequences, but they all are represented by oov_token index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6AKG-gv4gSW"
   },
   "source": [
    "Now let's increase num_words to 6 to represent most common 5 words in sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1677398576460,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "8NTYNW4ss7P7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=6, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgYDNqZhuz_V"
   },
   "source": [
    "Let's print **word_counts** first. Here the count of oov_token is not shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1677398583565,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "BnFM1AwPusCf",
    "outputId": "204cd487-4c99-481a-bd38-6e55bb548e94",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('you', 2),\n",
       "             ('take', 2),\n",
       "             ('the', 3),\n",
       "             ('blue', 1),\n",
       "             ('pill', 2),\n",
       "             ('story', 1),\n",
       "             ('ends', 1),\n",
       "             ('or', 1),\n",
       "             ('red', 1)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9Spc1Jy1uYu"
   },
   "source": [
    "Although not seen in tokenizer.word_counts, below we can see that the most common token is the oov_token represented as index 1 in the train_sequences.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1677398586973,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "wA7mcFjotEye",
    "outputId": "e965165b-57d5-4e36-de39-e368838036b2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'the': 2, 'you': 3, 'take': 4, 'pill': 5, 'blue': 6, 'story': 7, 'ends': 8, 'or': 9, 'red': 10}\n",
      "['You take the blue pill.', 'The story ends...', 'or you take the red pill.']\n",
      "[[3, 4, 2, 1, 5], [2, 1, 1], [1, 3, 4, 2, 1, 5]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)\n",
    "print(train_texts)\n",
    "print(train_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3VZzcXO5EWH"
   },
   "source": [
    "We can summarize the process in the image given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src = \"./Images/Tokenizer_6.jpg\" />"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "authorship_tag": "ABX9TyO/yXUK1fmmM+cZkhxQhNRj",
   "mount_file_id": "1YO0jttRcG7EsuokAebKWId06K9FysD_A",
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.11.0 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.11-cpu-py39-ubuntu20.04-sagemaker-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
