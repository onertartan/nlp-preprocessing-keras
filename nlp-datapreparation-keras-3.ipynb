{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MrawafSittz"
   },
   "source": [
    "# Content\n",
    "This notebook is the third part of  Data Preparation in NLP using Keras.   \n",
    "  \n",
    " In this notebook we will see how we can pad sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlb79hoSCPxP"
   },
   "source": [
    "Before explaining padding, let's repeat the necessary steps first.<br>\n",
    "1. Create training and test texts\n",
    "2. Create tokenizer with num_words and oov_token parameters\n",
    "3. Fit the tokenizer on the traning corpus\n",
    "4. Convert training and test texts to sequences\n",
    "5. Check the word_index and resulting sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-TPSzEfDjPM"
   },
   "source": [
    "1. Create training and test texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1677399916479,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "PhCgPye7KbW4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "train_texts = [\"If you take the blue pill.\",\n",
    "             \"The story ends.\",\n",
    "             \"You choose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677399916910,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "hbhweTiDLGaB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_texts = [\"If you take the red pill.\",\n",
    "             \"You stay in wonderland.\",\n",
    "             \"You must choose\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC_fhvMfDo6t"
   },
   "source": [
    "2. Create tokenizer with num_words and oov_token parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677399918124,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "Kzzq3pIIK3kv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100, oov_token=\"<OOV>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-nQi3MKDvX2"
   },
   "source": [
    "3. Fit the tokenizer on the traning corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1677399919560,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "a8sjwza4Dxh2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaiOgDLAD9RD"
   },
   "source": [
    "4. Convert training and test texts to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677399921061,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "UeEisMxcBEMO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrWCEie4Ec6X"
   },
   "source": [
    "5. Check the word_index and resulting sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1677399923055,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "hRlwXEZ_L6fp",
    "outputId": "7aa9911b-239d-450b-c1a0-29d964eacd3a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.word_index   :  {'<OOV>': 1, 'you': 2, 'the': 3, 'if': 4, 'take': 5, 'blue': 6, 'pill': 7, 'story': 8, 'ends': 9, 'choose': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"tokenizer.word_index   : \",tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677398651439,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "oHgRWfOELgcG",
    "outputId": "a4ddd908-540c-4f66-fec1-eac74e631218",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you take the blue pill.\n",
      "[4, 2, 5, 3, 6, 7]\n",
      "The story ends.\n",
      "[3, 8, 9]\n",
      "You choose\n",
      "[2, 10]\n"
     ]
    }
   ],
   "source": [
    "for train_text, train_seq in zip(train_texts,train_sequences):\n",
    "    print(train_text)\n",
    "    print(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677398652786,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "jSe2e8hZLh5-",
    "outputId": "6f26b17b-2701-4467-a274-06b65952d4da",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you take the red pill.\n",
      "[4, 2, 5, 3, 1, 7]\n",
      "You stay in wonderland.\n",
      "[2, 1, 1, 1]\n",
      "You must choose\n",
      "[2, 1, 10]\n"
     ]
    }
   ],
   "source": [
    "for test_text, test_seq in zip(test_texts,test_sequences):\n",
    "    print(test_text)\n",
    "    print(test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOKwu268KKo_"
   },
   "source": [
    "# **Padding sequences**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ9cgJHhNTEJ"
   },
   "source": [
    "As we see above, lengths of sequences vary based on the content. However, neural networks expect inputs with the same length.<br> In order to make sequences with the same length we pad sequences.<br>\n",
    "First we have to import pad_sequences from tensorflow.keras.preprocessing.sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le6GiLqNGZtG"
   },
   "source": [
    "* This function is used not only in NLP but also in other sequence models time-series etc.) <br>\n",
    "* We will use it to transform our sequences into a 2D Numpy array of shape **(number_of_sentences, number_of_words)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsiHLJPXRoVA"
   },
   "source": [
    "If we don't provide maxlen argument,  the length of the padded sequence will be the length of the longest sequence in the list.  <br>\n",
    "Shorter sequence will be padded with zeros from start(left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1677398658350,
     "user": {
      "displayName": "öner tartan",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "O4J7Y6JlLsu0",
    "outputId": "7ed8d16c-74ed-47fa-8deb-59d7cf6a66a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences_padded :\n",
      " [[ 4  2  5  3  6  7]\n",
      " [ 0  0  0  3  8  9]\n",
      " [ 0  0  0  0  2 10]]\n",
      "test_sequences_padded  :\n",
      " [[ 4  2  5  3  1  7]\n",
      " [ 0  0  2  1  1  1]\n",
      " [ 0  0  0  2  1 10]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "train_sequences_padded = pad_sequences(train_sequences)\n",
    "test_sequences_padded = pad_sequences(test_sequences)\n",
    "print(\"train_sequences_padded :\\n\",train_sequences_padded)\n",
    "print(\"test_sequences_padded  :\\n\",test_sequences_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./Images/Tokenizer_7.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c49FVBNSWKh"
   },
   "source": [
    "# maxlen parameter\n",
    "Using **maxlen** parameter we can specify the sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1644507685827,
     "user": {
      "displayName": "öner tartan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "-I4FkycqSKDK",
    "outputId": "3b8eea0b-d077-46a2-ad58-6509cacb25ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences_padded :\n",
      " [[ 0  0  0  0  3  4  5  2  6  7]\n",
      " [ 0  0  0  0  0  0  0  2  8  9]\n",
      " [ 0  0  0  0  0  0  0  0  0 10]]\n",
      "test_sequences_padded  :\n",
      " [[ 0  0  0  0  3  4  5  2  1  7]\n",
      " [ 0  0  0  0  0  0  4  1  1  1]\n",
      " [ 0  0  0  0  0  0  0  0  4 10]]\n"
     ]
    }
   ],
   "source": [
    "train_sequences_padded = pad_sequences(train_sequences,maxlen = 10)\n",
    "test_sequences_padded = pad_sequences(test_sequences, maxlen = 10)\n",
    "print(\"train_sequences_padded :\\n\",train_sequences_padded)\n",
    "print(\"test_sequences_padded  :\\n\",test_sequences_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCkdLvfnSuei"
   },
   "source": [
    "If **maxlen** parameter is smaller than a sequence, that sequence will be truncated from its beginning.<br>\n",
    "Notice that first sequences in train and test sequences are truncated as they lose the element at the beginnig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1643382454908,
     "user": {
      "displayName": "öner tartan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "zVvT_HOZOh8-",
    "outputId": "905339d7-8835-4175-b1e2-9ffc4d8c61a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences_padded :\n",
      " [[ 4  5  2  6  7]\n",
      " [ 0  0  2  8  9]\n",
      " [ 0  0  0  0 10]]\n",
      "test_sequences_padded  :\n",
      " [[ 4  5  2  1  7]\n",
      " [ 0  4  1  1  1]\n",
      " [ 0  0  0  4 10]]\n"
     ]
    }
   ],
   "source": [
    "train_sequences_padded = pad_sequences(train_sequences, maxlen = 5)\n",
    "test_sequences_padded = pad_sequences(test_sequences, maxlen = 5)\n",
    "print(\"train_sequences_padded :\\n\",train_sequences_padded)\n",
    "print(\"test_sequences_padded  :\\n\",test_sequences_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./Images/Tokenizer_8.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stUKpsb5Tl8r"
   },
   "source": [
    "# truncate parameter\n",
    "Using **truncating** parameter we can specify to remove values from sequences larger than maxlen, either at the beginning or at the end of the sequences.<br>\n",
    "The default option is **pre** as we have seen above using maxlen shorter than the first sequence.<br>\n",
    "Let's use the **post** option and see the difference on the first elements of the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1644508063647,
     "user": {
      "displayName": "öner tartan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "3aUcWn2WTop4",
    "outputId": "f2d912d2-f74d-450e-bbb8-fcfba15bf009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences_padded :\n",
      " [[ 3  4  5  2  6]\n",
      " [ 0  0  2  8  9]\n",
      " [ 0  0  0  0 10]]\n",
      "test_sequences_padded  :\n",
      " [[ 3  4  5  2  1]\n",
      " [ 0  4  1  1  1]\n",
      " [ 0  0  0  4 10]]\n"
     ]
    }
   ],
   "source": [
    "train_sequences_padded = pad_sequences(train_sequences,maxlen = 5, truncating = \"post\")\n",
    "test_sequences_padded = pad_sequences(test_sequences,maxlen = 5, truncating = \"post\")\n",
    "print(\"train_sequences_padded :\\n\",train_sequences_padded)\n",
    "print(\"test_sequences_padded  :\\n\",test_sequences_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./Images/Tokenizer_9.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "al1gktnmUaLs"
   },
   "source": [
    "# **padding** parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyWH6iNxU6fA"
   },
   "source": [
    "Using padding parameter, we can specify to pad either before or after each sequence.<br> The default option is **\"pre\"** as we have seen above.<br>\n",
    "Let's use the **post** option and see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1644508437797,
     "user": {
      "displayName": "öner tartan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15982345773583695137"
     },
     "user_tz": -180
    },
    "id": "mtbRdV5yVFPw",
    "outputId": "e901d753-41ea-4720-fc59-6bb75019fcb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences_padded :\n",
      " [[ 3  4  5  2  6]\n",
      " [ 2  8  9  0  0]\n",
      " [10  0  0  0  0]]\n",
      "test_sequences_padded  :\n",
      " [[ 3  4  5  2  1]\n",
      " [ 4  1  1  1  0]\n",
      " [ 4 10  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "train_sequences_padded = pad_sequences(train_sequences,maxlen = 5, truncating = \"post\", padding = \"post\")\n",
    "test_sequences_padded = pad_sequences(test_sequences,maxlen = 5, truncating = \"post\",padding = \"post\")\n",
    "print(\"train_sequences_padded :\\n\",train_sequences_padded)\n",
    "print(\"test_sequences_padded  :\\n\",test_sequences_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/Tokenizer_10.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7A7G2yikr4J"
   },
   "source": [
    "In this notebook series we have learnt how to prepare textual data as inputs for neural networks using Keras library. <br>\n",
    "In the next series we will use these techniques when working with recurrent neural networks.\n",
    "\n",
    "Note: We will usually set truncating and padding parameters as \"post\"."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "authorship_tag": "ABX9TyN0ofjEZJQ/vCmK7Q02Bwt2",
   "mount_file_id": "1zkeUZ_rwYk09gHSEN0l_O7OckApSBust",
   "provenance": [
    {
     "file_id": "1iARifvfUuyYAMan0w0RnVrQPTjr9x8uI",
     "timestamp": 1644343431393
    }
   ]
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.11.0 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.11-cpu-py39-ubuntu20.04-sagemaker-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
